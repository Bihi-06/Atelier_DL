# ğŸ“° Arabic News Semantic Scoring with Sentence Transformers

This project involves scraping Arabic news articles from Al Jazeera, analyzing their semantic similarity to a reference sentence using a multilingual **Sentence Transformer**, and scoring them accordingly. The ultimate goal is to build a dataset for potential fine-tuning of language models or for further NLP research.


---

##  What I Learned (Synthesis)

Through this lab, I gained practical experience in combining multiple key areas of Natural Language Processing and Machine Learning workflows:

- ğŸŒ **Multilingual NLP**: Learned how to use sentence-transformers for understanding Arabic language semantics.
- ğŸ§  **Semantic Similarity**: Understood the importance of sentence embeddings and cosine similarity in assessing the meaning of text.
- ğŸ§¼ **Data Preprocessing**: Applied effective Arabic text cleaning and tokenization techniques, including the use of NLTK's stopword removal.
- ğŸ•·ï¸ **Web Scraping**: Built a custom scraper to extract real-world Arabic news data from Al Jazeera using BeautifulSoup.
- ğŸ“Š **Dataset Creation**: Transformed raw scraped data into a structured dataset ready for training or evaluation.
- ğŸ”— **Model Integration**: Integrated pre-trained models like `paraphrase-multilingual-MiniLM-L12-v2` into a real-world pipeline.
- ğŸ” **Evaluation Metrics**: Used semantic scores (on a 0â€“10 scale) to quantify relevance of news content to a given reference topic.

This hands-on lab reinforced both foundational and advanced skills essential in building real-world AI/NLP applications.


## ğŸ“Œ Features

- **Web Scraping**: Automatically scrapes Arabic news articles from Al Jazeera.
- **Text Preprocessing**: Cleans and tokenizes Arabic text.
- **Semantic Scoring**: Uses a multilingual Sentence Transformer to calculate similarity with a reference sentence.
- **Dataset Creation**: Stores the scraped and processed data into a structured CSV file.
- **Future Ready**: Ready for integration into a fine-tuning pipeline using Transformers.

---

## ğŸ› ï¸ Technologies Used

- Python
- `sentence-transformers`
- `transformers` (HuggingFace)
- `nltk`
- `beautifulsoup4`
- `pandas`
- `scikit-learn`
- PyTorch

---

## ğŸš€ Installation

First, make sure you have Python â‰¥ 3.7. Install required packages:

```bash
pip install sentence-transformers transformers beautifulsoup4 nltk datasets accelerate
```

---

## ğŸ“‚ Project Structure

```
atelier3.ipynb         # Main notebook
arabic_dataset.csv     # Output CSV dataset (after running)
```

---

## ğŸ“‹ How It Works

### 1. Reference Definition
Defines a reference sentence in Arabic:
```python
reference = "Ù‡Ø°Ø§ Ø§Ù„Ù†Øµ ÙŠØªØ­Ø¯Ø« Ø¹Ù† Ø§Ù„ØªØ¹Ù„ÙŠÙ… ÙÙŠ Ø§Ù„ÙˆØ·Ù† Ø§Ù„Ø¹Ø±Ø¨ÙŠ"
```

### 2. Article Scraping
Scrapes recent Arabic news articles from Al Jazeera using BeautifulSoup.

### 3. Preprocessing
- Cleans HTML.
- Retains Arabic-only characters.
- Removes stopwords and short words using NLTK's Arabic stopword list.

### 4. Semantic Similarity
Computes similarity between each article and the reference using:
```python
sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2
```
The result is scaled into a 0â€“10 score.

### 5. Dataset Creation
Stores the result as:
```csv
Text, Score, tokens
```

---

## ğŸ§ª Sample Output

| Text (truncated)        | Score | Tokens                  |
|-------------------------|-------|--------------------------|
| "ÙÙŠ Ø®Ø·ÙˆØ© Ø¬Ø¯ÙŠØ¯Ø©..."       | 8.45  | [Ø®Ø·ÙˆØ©, Ø¬Ø¯ÙŠØ¯Ø©, ...]       |

---

## ğŸ“ˆ Potential Extensions

- Fine-tune GPT-2 or other LLMs using the generated data.
- Extend scraping to multiple Arabic sources.
- Create datasets for other semantic tasks: classification, summarization, etc.

---

## ğŸ“œ License

This project is open-source and available under the MIT License.
